\chapter{线性代数与微积分}

\section{微分学}

为了得到定义在$\mathbb{R}^n$上的函数的导数与微分的定义，回顾一下一元函数微分学的一些内容，看看怎样把$n=1$的情形解释一下，进而可以自然地推广到$n>1$的情况.

设$f$是定义在$(a,b)\subset \mathbb{R}$上的函数，$x\in(a,b)$，那么$f$在$x$处的导数定义为
\[f'(x)=\lim_{h\to 0}\frac{f(x+h)-f(x)}{h}.\]



为了更好地处理多元函数的微分学，我们先考虑一下线性映射的范数：

\begin{definition}{线性映射的范数}{}
    对于线性映射 $A\in L(\mathbb{R}^n, \mathbb{R}^m)$ 与 $x\in\mathbb{R}^n$，定义 $A$ 的\term{范数} $\Vert A \Vert$ 为 $\Vert A \Vert = \sup\limits_{\vert x\vert\leqslant 1} \vert Ax\vert$.
\end{definition}

这样定义的范数其实反映出了线性映射伸张向量的能力，根据\[\Vert A\Vert = \sup\limits_{x\neq 0}\vert A\frac{x}{\vert x\vert}\vert = \sup\limits_{x\neq 0}\frac{\vert Ax\vert}{\vert x\vert},\]以及\[\vert Ax\vert = \vert x\vert \vert A\frac{x}{\vert x\vert}\vert \leqslant \vert x\vert \Vert A\Vert,\]这样就可以定义线性映射 $A$ 在 $x$ 方向的\term{伸张系数}$\frac{\vert Ax\vert}{\vert x\vert}$，并且 $\Vert A\Vert$ 的几何意义是一切方向的伸张系数的上确界.

注意到，对于一般的线性空间 $X$，如果范数选取得当，就算是 $X$ 是无穷维的，我们对线性映射定义的范数也是有意义的，但我们敏锐的嗅觉告诉我们，既然加上了“无穷维”这个不容易处理的条件，无穷维线性空间之间的线性映射的性质就会变得更加复杂，我们暂且不对其继续深入讨论.

作为范数，首先要满足下面四条性质：

\begin{theorem}{}{}
    设 $A\in L(\mathbb{R}^n, \mathbb{R}^m),\enspace B\in L(\mathbb{R}^l, \mathbb{R}^n)$，则
    \begin{enumerate}
        \item $\Vert A\Vert\geqslant 0$，且 $\Vert A\Vert=0$ 当且仅当 $A=0$；
        \item 若$\lambda\in R$，$\Vert \lambda A\Vert=\vert\lambda\vert\Vert A\Vert$；
        \item $\Vert A+B\Vert\leqslant\Vert A\Vert+\Vert B\Vert$；
        \item $\Vert AB\Vert\leqslant\Vert A\Vert\Vert B\Vert$.
    \end{enumerate}
\end{theorem}

\begin{proof}
    \begin{enumerate}
        \item 显然；
        \item $\Vert \lambda A\Vert=\sup\limits_{\vert x\vert\leqslant 1}\vert \lambda Ax\vert=\vert\lambda\vert\sup\limits_{\vert x\vert\leqslant 1}\vert Ax\vert=\vert\lambda\vert\Vert A\Vert$；
        \item $\Vert A+B\Vert=\sup\limits_{\vert x\vert\leqslant 1}\vert (A+B)x\vert = \sup\limits_{\vert x\vert\leqslant 1}\vert Ax + Bx\vert\leqslant\sup\limits_{\vert x\vert\leqslant 1}\vert Ax\vert+\sup\limits_{\vert x\vert\leqslant 1}\vert Bx\vert=\Vert A\Vert+\Vert B\Vert$；
        \item $\Vert AB\Vert=\sup\limits_{\vert x\vert\leqslant 1}\vert ABx\vert=\sup\limits_{\vert x\vert\leqslant 1}\vert A(Bx)\vert\leqslant\sup\limits_{\vert x\vert\leqslant 1}\Vert A\Vert\vert Bx\vert\leqslant\Vert A\Vert\sup\limits_{\vert x\vert\leqslant 1}\vert Bx\vert=\Vert A\Vert\Vert B\Vert$.
    \end{enumerate}
\end{proof}

\begin{example}{另一种范数}{}
    对于线性映射 $A\in L(\mathbb{R}^m, \mathbb{R}^n)$，其矩阵表示为 $M(A)$，定义 $A$ 的范数为 \[\Vert A\Vert_2 = \sqrt{\sum_{i=1}^{m}\sum_{j=1}^{n}a_{ij}^2}.\]
    请验证其满足范数的四条性质.
\end{example}

\begin{proof}

\end{proof}

线性映射终归也是一个“线性的函数”，所以自然可以考虑它的有界性和连续性：

\begin{definition}{赋范线性空间上的有界映射}{}
    设 $A$ 是赋范线性空间 $X$ 到赋范线性空间 $Y$ 的线性映射，如果存在常数 $M\leqslant 0$ 使得对于任意 $x\in X$，都有 \[\Vert Ax\Vert\leqslant M\vert x\vert,\]
    那么称 $A$ 是\term{有界映射}.
\end{definition}

\begin{theorem}{}{}
    对于线性赋范空间 $X$ 和 $Y$，从$X$ 到 $Y$ 的线性映射 $A$ 是有界映射的充分必要条件是 $A$ 将所有有界集映射为有界集.
\end{theorem}

\begin{proof}
    设 $A$ 将所有有界集映射为有界集，那么 $A$ 将单位球面 $S=\{x\in X\vert\Vert x\Vert=1\}$ 映射为一个有界集，那么存在常数 $M\leqslant 0$ 使得对于 $y\in S$ 有 $\Vert Ay\Vert\leqslant M$，当 $x = 0$ 的时候，$\Vert Ax\Vert \leqslant M\vert x\vert$自然成立，当 $x \neq 0$ 的时候，取 $y=\frac{x}{\vert x\vert}$，那么 \[\frac{\Vert Ax\Vert}{\vert x\vert} = \Vert A\frac{x}{\vert x\vert}\Vert = \Vert Ay\Vert \leqslant M.\] 这就说明了 $A$ 为有界映射.

    反过来，如果 $A$ 是有界映射，设 $B$ 是 $X$ 中的有界集，那么存在常数 $N$ 使得对于任意 $x\in B$ 都有 $\vert x\vert\leqslant N$，那么对于任意 $x\in B$，有 \[\Vert Ax\Vert\leqslant M\vert x\vert\leqslant MN,\]这就说明了 $A$ 将有界集映射为有界集.
\end{proof}

\begin{definition}{距离空间上的连续映射}{}
    假设 $(X,d_X)$ 和 $(Y, d_Y)$ 是两个距离空间，$f: X\to Y$ 是这两个距离空间的映射. 假设 $x_0\in X$，$y_0 = f(x_0)\in Y$. 如果对于任意的 $\varepsilon>0$，都存在 $\delta>0$ 使得对于任意满足 $d_X(x, x_0) < \delta$ 的 $x\in X$，都有 $d_Y(f(x), y_0) < \varepsilon$，那么称 $f$ 在 $x_0$ 处\term{连续}. 如果 $f$ 在 $X$ 的每一点都连续，那么称 $f$ 是\term{连续映射}.
\end{definition}

赋范线性空间 $(X, \Vert \cdot \Vert)$ 当然是度量空间，对于 $x, y\in X$，只需要定义 $d(x, y) = \Vert x-y\Vert$ 就可以得到一个度量，而线性映射相比于一般的映射，理应具有更强的性质，我们下面证明这一点：

\begin{theorem}{赋范线性空间上的连续映射}{}
    设 $A$ 是赋范线性空间 $X$ 到赋范线性空间 $Y$ 上的线性映射，假设 $A$ 在某一点 $x_0\in X$ 处连续，那么 $A$ 是 $X$ 上的连续映射.
\end{theorem}

\begin{proof}

\end{proof}

\begin{theorem}{有界性和连续性的等价性}{}
    从赋范线性空间 $X$ 到赋范线性空间 $Y$ 上的线性映射 $A$ 是有界映射的充分必要条件是 $A$ 是连续映射.
\end{theorem}

更进一步的，如果 $A\in L(\mathbb{R}^n, \mathbb{R}^m)$ 那么可以直接得到 $A$ 是有界且一致连续的. 当我们取 $\mathbb{R}^n$ 上的一组标准基 $\{e_1, e_2, \cdots, e_n\}$，设 $x\in \mathbb{R}^N$，$\vert x\vert \leqslant 1$，那么 $x$ 就可以表示为 $x = \ds\sum_{i=1}^{n} x_ie_i$，$\vert x_i \vert \leq 1$. 于是
\[\vert Ax\vert = \vert \sum_{i=1}^{n} x_iAe_i\vert \leqslant \sum_{i=1}^{n}\vert x_i\vert\vert Ae_i\vert \leqslant \sum_{i=1}^{n}\vert Ae_i\vert.\]
所以\[\Vert A\Vert \leqslant \sum_{i=1}^{n}\vert Ae_i\vert < \infty.\]
并且因为当 $x, y\in \mathbb{R}^n$ 时，$\vert Ax - Ay \vert \leqslant \Vert A\Vert\vert x-y\vert$，所以 $A$ 是一致连续的.

这下我们在 $L(\mathbb{R}^n, \mathbb{R}^m)$ 上有了范数，自然可以定义度量、开集、连续等概念，下面对于可逆线性算子的刻画就利用了这些概念：

\begin{theorem}{}{}
    设 $\Omega$ 为 $\mathbb{R}^n$ 上所有可逆线性算子的集合.
    \begin{enumerate}
        \item 若 $A\in \Omega$，$B\in L(\mathbb{R}^n)$，并且 \[\Vert B-A\Vert\cdot\Vert A^{-1}\Vert < 1,\]那么 $B\in \Omega$；
        \item $\Omega$ 是 $L(\mathbb{R}^n)$ 的开集，映射 $A\to A^{-1}$ 是 $\Omega$ 上的连续映射.
    \end{enumerate}
\end{theorem}

\begin{proof}
    \begin{enumerate}
        \item
        \item
    \end{enumerate}
\end{proof}

\begin{definition}{多元函数的微分}{}

\[\lim\limits_{h\to 0}\frac{\vert f(x_0 + h) - f(x_0) - Ah \vert}{\vert h \vert} = 0.\]

\end{definition}


回忆一下从一元函数到多元向量值函数的推广过程：在一元函数，我们研究的主要是导数，导数的实际意义是函数的变化率，一元函数的自变量只有一个，表示自变量的点只能在直线上变动，移动的方向也只有左右两个方向；而当我们想在多元函数上讨论函数的变化率的时候，我们忽然发现，表示自变量的点可以在一个区域内任意移动了，不仅可以移动距离，而且可以按任意方向移动同一段距离. 因此函数的变化不仅与移动的距离有关，还与移动的方向有关，所以我们尝试考虑某一个方向上函数的变化率，当方向被限制在坐标轴方向的时候，我们就得到\term{偏导数}，当我们考虑某一个方向 $\vec{v}$ 上的变化率的时候，我们就得到\term{方向导数}. 可是我们不想仅限于此，我们注意到可以将方向 $\vec{v}$ 分解为坐标轴方向的向量的和，而我们恰恰有函数在坐标轴方向上的变化率——偏导数，所以我们可以将函数在方向 $\vec{v}$ 上的变化率表示为函数在坐标轴方向上的变化率的线性组合，这也就是微分的想法.

\begin{theorem}{方向导数与微分}{}
    对函数 $f: \mathbb{R}^n\to \mathbb{R}$，设 $f$ 在 $x_0$ 处可微，那么 $f$ 在 $x_0$ 处的方向导数都存在，并且有\[\frac{\partial f}{\partial u}(x_0) = \mathrm{d}f(x_0)(u).\]
    并且 $f$ 在 $x_0$ 的偏导数 $f_{x_i}(x_0)$ 都存在，记 $f$ 在 $x_0$ 处的\term{梯度}为 \[\nabla f(x_0) = (f_{x_1}(x_0), f_{x_2}(x_0), \cdots, f_{x_n}(x_0)),\]
    那么就有 \[\mathrm{d}f(x_0)(u) = \nabla f(x_0)\cdot u.\]这就表明了\textrm{梯度其实是微分的矩阵表示}.
\end{theorem}

\begin{proof}

\end{proof}

既然函数就是两个集合之间的映射，迄今为止我们考虑的一直是$\mathbb{R}^n$上的实值函数，既然线性映射都可以是从$\mathbb{R}^n$到$\mathbb{R}^m$的，那么函数当然也可以这样，这就是\term{向量值函数}.

向量值函数只是只是对于函数到达空间的简单推广，甚至在一般的度量空间之间的映射的视角，这仅仅只是一个特例而已. 我们知道，对于一元函数与多元函数在某一点处的微分其实是一个线性映射 $L$，使得其是在这点处的最佳线性逼近. 换句话说就是\[f(x) - f(x_0) = L(x-x_0) + o(\vert x-x_0\vert)\quad (f\to x_0).\]我们按照这样的思路，可以定义多元向量值函数的微分：

\begin{definition}{向量值函数的微分}{}
    设 $D\subset\mathbb{R}^n$ 是开集，$f: D\to\mathbb{R}^m$ 是一个向量值的多元函数函数，$x_0\in D$. 如果存在一个线性映射 $L\in L(\mathbb{R}^n, \mathbb{R}^m)$ 使得在 $x_0$ 附近成立\[f(x) - f(x_0) = L(x-x_0) + o(\vert x-x_0\vert)\quad (f\to x_0),\]那么称 $f$ 在 $x_0$ 处\term{可微}，并且称 $L$ 为 $f$ 在 $x_0$ 处的\term{微分}，记作 $df(x_0)$.
\end{definition}

从经验上看，向量值函数与其微分的出现是自然而必然的，对于一个一般的多元函数 $f: \mathbb{R}^n\to \mathbb{R}$，我们定义了它的微分是一个线性映射 $\mathrm{d}f\in L(\mathbb{R}^n, \mathbb{R})$，按照一维的理论，对一次导数求导就得到了二次导数，所以我们应该对 $x \mapsto \mathrm{d}f$ 求微分，而这实际上是一个 $\mathbb{R}^n\to L(\mathbb{R^n},\mathbb{R})\simeq \mathbb{R}^n$ 的函数. 你看，这就是向量值函数！所以我们自然要定义向量值函数与其微分.

再者，从换元的角度，对于一个二元函数 $f(x, y)$，我们可以随便找一个换元 $x = x(u, v)$ 与 $y = y(u, v)$，那么 $f(x, y)$ 就变成了 $f(x(u, v), y(u, v))$，将换元后的函数视作一个复合函数 $f\circ \varphi$，那么 $\varphi$ 必须是从 $\mathbb{R}^2$ 到 $\mathbb{R}^2$ 的，也就是 $\varphi(u, v) = (x(u, v), y(u, v))$. 这就是向量值函数的另一个实例.

从一元函数到多元函数，对微分的定义其实迈上了一个新的台阶，原因其实是自变量的每一个分量“杂糅”在一起，我们需要单独将每一个分量“拎出来”单独讨论，所以这就是偏导数与全微分的来源. 但是对于向量值函数而言，它的每一个分量并没有什么特别强的联系——这是因为我们有了坐标，并且这严重依赖于坐标系的选取——所以我们可以将从 $\mathbb{R}^n$ 到 $\mathbb{R}^m$ 的向量值函数拆成 $m$ 个分量，每一个分量都是从 $\mathbb{R}^n$ 到 $\mathbb{R}$ 的函数. 在这个角度上，我们可以直接但是不严谨地得出：向量值函数 $f$ 在 $x_0$ 处可微当且仅当其每一个分量 $f_i$ 在 $x_0$ 处都可微，并且其微分为
\[
    \mathrm{d}f(x_0) = Jf(x_0) =
    \begin{pmatrix} \nabla f_1(x_0) \\ \nabla f_2(x_0) \\ \vdots \\ \nabla f_n(x_0) \end{pmatrix} =
    \begin{pmatrix}
        \dfrac{\partial f_1}{\partial x_1}(x_0) &\dfrac{\partial f_1}{\partial x_2}(x_0) & \cdots & \dfrac{\partial f_1}{\partial x_n}(x_0) \\
        \dfrac{\partial f_2}{\partial x_1}(x_0) & \dfrac{\partial f_2}{\partial x_2}(x_0) & \cdots & \dfrac{\partial f_2}{\partial x_n}(x_0) \\
        \vdots & \vdots & \ddots & \vdots \\
        \dfrac{\partial f_m}{\partial x_1}(x_0) & \dfrac{\partial f_m}{\partial x_2}(x_0) & \cdots & \dfrac{\partial f_m}{\partial x_n}(x_0)
    \end{pmatrix}.
\]
其中矩阵 $Jf(x_0)$ 是 $f$ 在 $x_0$ 的微分的矩阵表示，被称为\textrm{Jacobi 矩阵}. 虽然这非常符合直觉，但是我们还是需要严谨的证明：

\begin{theorem}{微分的计算}{}
    假设 $V = \mathbb{R}^n$ 和 $W = \mathbb{R}^m$，我们分别取坐标系 $\{x_i\}_{i = 1, 2, \cdots, n}$ 和 $\{y_j\}_{j = 1, 2, \cdots, m}$，考虑函数 \[f: V\to W,\enspace x\mapsto f(x) = (f_1(x_1, x_2, \cdots, x_n), \cdots, f_m(x_1, x_2, \cdots, x_n)).\]
    那么 $f$ 在 $x_0$ 处可微当且仅当每一个 $f_i$ 在 $x_0$ 处都可微，并且微分 $\mathrm{d}f(x_0)\in L(\mathbb{R}^n, \mathbb{R}^m)$ 的矩阵表示为
    \[\left(\frac{\partial f_i}{\partial x_j}(x_0)\right)_{\begin{subarray}  \enspace i = 1, 2, \cdots, m \\ j = 1, 2, \cdots, n\end{subarray}}.\]
\end{theorem}

\begin{proof}

\end{proof}

另外需要注意的是，

\begin{theorem}{链式法则}{}
    设 $D$ 和 $\Delta$ 分别为 $\mathbb{R}^n$ 和 $\mathbb{R}^m$ 上的开集，$f: D\to \mathbb{R}^m$ 和 $g: \Delta\to \mathbb{R}^l$ 为向量值函数，且 $f(D)\subset \Delta$. 如果 $f$ 在 $x_0\in D$ 中可微，$g$ 在 $y_0 = f(x_0)$ 处可微，那么复合函数 $h = g\circ f$ 在 $x_0$ 处可微，并且有\[Jh(x_0) = Jg(y_0)Jf(x_0).\]

    （画两个交换图）
\end{theorem}

\begin{proof}

\end{proof}

\begin{corollary}{反函数的微分}{}
    给定区域 $D\subset \mathbb{R}^n$ 和 $\Delta \subset \mathbb{R}^m$ 与向量值函数 $f: D\to \Delta$，如果 $f$ 是一一映射并且其逆映射 $f^{-1}: \Delta\to D$ 是可微的，那么有
    \begin{enumerate}
        \item[(1)] $m = n$；
        \item[(2)] $Jf(x)$ 是可逆的，并且有 \[J(f^{-1})(y) = [\left.Jf(x)\right|_{x = f^{-1}(y)}]^{-1}.\]
    \end{enumerate}
\end{corollary}

\begin{proof}
    我们令 $\Omega = D$，$g = f^{-1}: \Omega\to\Delta$，那么有 $g \circ f = \mathrm{id}_{\Omega}$，根据链式法则有 \[\mathrm{Id}_{\Omega} = I_{n} = J(g\circ f)(x_0) = Jg(y_0)\cdot Jf(x_0),\]
    反过来用 $f^{-1}$ 替代 $f$ 可得另一侧\[\mathrm{Id}_{\Delta} = I_m = J(f\circ g)(y_0) = Jf(x_0)\cdot Jg(y_0).\]
    根据线性代数的知识，很容易可以看出 $Jf(x)$ 和 $Jg(g)$ 都需要是一个方阵，这就是 (1). 并且也足以说明 $Jf(x)$ 是可逆的，也就是$Jg(y) = (Jf(x))^{-1}.$
\end{proof}

与一元函数的微分中值定理相似，我们也有多元函数的微分中值定理：

\begin{theorem}{微分中值定理}{}
    设 $D\subset \mathbb{R}^n$ 为凸域，函数 $f:D\to \mathbb{R}$ 在 $D$ 中处处可微，则任给 $x,y\in D$，存在 $\theta\in (0, 1)$ 使得\[f(y) - f(x) = \nabla f(\xi)\cdot(y-x),\enspace \xi=\theta x + (1-\theta)y.\]
\end{theorem}

\begin{proof}

\end{proof}

一个很自然的问题就是微分中值定理可不可以推广到向量值函数？设 $D\subset \mathbb{R}^n$ 为凸域，$f: D\to \mathbb{R}^m$ 是一个向量值函数，$x, y\in D$，对 $f$ 的每一个分量 $f_i$ 应用微分中值定理可以得到\[f_i(x) - f_i(y) = \nabla f_i(\xi_i)\cdot(x-y),\]其中 $\xi_i\in D$，注意到这些 $xi_i$ 未必相同，比如对于函数 $f: \mathbb{R}\to\mathbb{R}^2,\enspace f(t) = (t^2, t^3)$，取 $x = 1$，$y = 0$，通过计算得知 $\xi_1 = \dfrac{1}{2}$，$\xi_2 = \pm\dfrac{1}{\sqrt{3}}$，因此 $\xi_1 \neq \xi_2$. 这就表明我们不能指望着 $f(x) - f(y) = Jf(\xi)(x-y)$ 对于某一个 $\xi$ 成立. 但是我们却可以有另一个不错的估计，这就是\term{拟微分中值定理}.

\begin{theorem}{拟微分中值定理}{}
    设$D\subset \mathbb{R}^n$ 为凸域，$f: D\to \mathbb{R}^m$ 在 $D$ 中处处可微，则任给 $x, y\in D$，存在 $\xi\in D$ 使得\[\vert f(x) - f(y)\vert \leqslant \Vert Jf(\xi)\Vert\cdot \vert x - y\vert.\]
\end{theorem}

证明的基本想法是对 $f$ 的分量的线性组合应用微分中值定理，然后进行放缩.

\begin{proof}
    不妨设 $f(x) \neq f(y)$，任意取定 $\mathbb{R}^m$ 中的单位向量 $u = (u_1, u_2, \cdots, u_m)$，记\[g = u\cdot f = \sum_{i = 1}^{m}u_if_i.\]
    则 $g$ 为 $D$ 中的可微函数，并且对 $x, y$ 存在 $\xi\in D$ 使得 \[g(x) - g(y) = \nabla g(\xi)\cdot (x - y).\]
    且 \[\nabla g(\xi) = \sum_{i = 1}^{m}u_i\nabla f_i(\xi).\]
    利用 Cauchy-Schwarz 不等式，有 \[\vert \nabla g(\xi)\vert \leqslant \sum_{i = 1}^m\vert u_i\vert \vert \nabla f_i(\xi)\vert \leqslant \left(\sum_{i = 1}^m\vert u_i\vert^2\right)^{\frac{1}{2}}\left(\sum_{i = 1}^m\vert \nabla f_i(\xi)\vert^2\right)^{\frac{1}{2}} = \Vert Jf(\xi)\Vert.\]
    由 $g(x) - g(y) = u\cdot (f(x) - f(y))$，我们有 \[\vert u \cdot [f(x) - f(y)]\vert = \vert g(x) - g(y) \vert \leqslant \vert \nabla g(\xi)\vert \cdot \vert x - y\vert \leqslant \Vert Jf(\xi)\Vert\cdot \vert x - y\vert.\]
    取 $u = \dfrac{f(x) - f(y)}{\vert f(x) - f(y)\vert}$ 就完成了证明.
\end{proof}

拟微分中值定理告诉我们，雅各布矩阵的范数可以用来估计向量值函数的改变量. 下面的结果给出了向量值函数与其线性化映射之间的误差估计.

\begin{corollary}{}{}
    设 $D\subset \mathbb{R}^n$ 为开集，$f: D\to \mathbb{R}^m$ 在 $D$ 中处处可微，且 $Jf(x)$ 关于 $x$ 连续，如果 $C\subset D$ 为紧凸集，则任给 $\varepsilon>0$，存在 $\delta>0$ 使得对于任意 $u, v\in C$，只要 $\vert u-v\vert < \delta$，就有\[\vert f(u) - f(v) - Jf(v)(u-v)\vert\leqslant \varepsilon\vert u-v\vert.\]
\end{corollary}

\begin{proof}

\end{proof}

既然我们可以对一个函数的反函数求微分，回想起对于一元函数，如果它可微并且导数处处非零，那么该函数存在反函数并且反函数可微. 那么一个自然的问题就是：在什么样的条件下，多元向量值函数存在反函数并且反函数可微呢？这就是\term{反函数定理}. 在考虑反函数定理之前，我们先看一个小小的比喻.

\begin{example}{}{}
    设 $A$ 是一个 $n$ 阶方阵，如果 $\Vert A\Vert < 1$，则 $I_n - A$ 可逆.
\end{example}

\begin{proof}
    设 $u\in \mathbb{R}^n$，如果 $(I_n - A)u = 0$，则 $\vert u\vert = \vert Au\vert \leqslant \Vert A\Vert \vert u\vert < \vert u\vert$，那么 $u$ 只能等于 $0$，所以 $I_n - A$ 是单射，所以其可逆.
\end{proof}

以分析学的视角看：给定 $v\in \mathbb{R}^n$，解方程 \[(I_n - A)x = v,\enspace\text{亦即}\enspace x = Ax+u.\]
我们先考虑映射 $\varphi(x) = Ax+v$，当 $x,y\in \mathbb{R}^n$ 时，\[\vert \varphi(x) - \varphi(y)\vert = \vert A(x - y)\vert\leqslant \Vert A\Vert\cdot \vert x - y\vert.\]

这个性质很不错，回忆一下\term{压缩映射原理}：

\begin{theorem}{压缩映射原理}{}
    设 $(X,d)$ 是一个完备的度量空间，$C$ 是一个非空闭子集，$f: C\to C$ 是一个压缩映射，即存在常数 $0\leqslant k < 1$ 使得对于任意 $x, y\in C$ 都有 \[d(f(x), f(y))\leqslant kd(x, y),\]那么 $f$ 在 $C$ 上有唯一的不动点. 即存在唯一的 $x_*\in C$ 使得 $f(x_*) = x_*$.
\end{theorem}

\begin{proof}
    任取 $a_0 \in C$，当 $n\geqslant 1$ 时，利用 $a_n = f(a_{n-1})$ 可以递归定义 $C$ 中的数列 $\{a_n\}$，我们来说明 $\{a_n\}$ 为 Cauchy 列. 根据题设，存在 $0\leqslant L <1$，使得当 $n\geqslant 1$ 时，\[d(a_{n+1}, a_n) = d(f(a_n), f(a_{n-1}))\leqslant Ld(a_n, a_{n-1}).\]
    由上式与归纳法可知 $d(a_n,a_{n-1})\leqslant L^{n-1}d(a_1, a_0)$ 对 $n\geqslant 1$ 均成立，当 $m > n$ 时，有
    \[\begin{aligned}
        d(a_m, a_n) & \leqslant d(a_m, a_{m-1}) + d(a_{m-1}, a_{m-2}) + \cdots + d(a_{n+1}, a_n) \\
        & \leqslant (L^{m-1} + L^{m-2} + \cdots + L^{n})d(a_1, a_0) \\
        & \leqslant \frac{L^n}{1-L}d(a_1, a_0).
    \end{aligned}\]
    由于 $L < 1$，所以当 $n\to\infty$ 时，$L^n\to 0$，所以 $\{a_n\}$ 为 Cauchy 列，其极限记为 $a_*$，则 $a_*\in C$，由 $a_n = f(a_{n-1})$ 与 $f$ 的连续性可知 $f(a_*) = a_*$.

    下面证明唯一性：若另有 $a\in C$ 使得 $f(a) = a$，则\[d(a, a_*) = d(f(a), f(a_*))\leqslant Ld(a, a_*),\]由于 $0\leqslant L < 1$，所以 $d(a, a_*) = 0$，即 $a = a_*$.
\end{proof}

所以这是一个压缩映射，因此 $\varphi$ 有唯一的不动点，即存在唯一的 $x_*\in \mathbb{R}^n$ 使得 $x_* = Ax_* + v$，即 $(I_n - A)x_* = v$，所以 $I_n - A$ 为单射，即可逆.

对于恒同映射 $I_n$ 来讲，范数小于 $1$ 的映射相对于它是一个\textrm{微小扰动}，上面的例子告诉我们，对于一个像恒同映射这样的可逆映射施加一个微小扰动得到的映射是可逆的. 在一般的向量值函数中，微小扰动的例子丰富极了，因为每一个在某一点 $x_0$ 可微的向量值函数在该点都可以将其线性化，也就是分解成 $L(x - x_0) + o(\vert x - x_0\vert)$，将后一项视作微小扰动 $\varepsilon(x - x_0)$ ，所以我们可以猜测：如果向量值函数的微分在某一点 $x_0$ 可逆，那么存在 $x_0$ 的邻域 $U$ 与 $y_0 = f(x_0)$ 的邻域 $V$ 使得 $\left.f\right|_U: U\to V$ 是可逆的. 不过我们需要对这个函数添加一定的可微性条件. 一个向量值函数是 $C^k$ 的是指其每个分量都是一个 $k$ 次连续可微函数. 这就是\term{反函数定理}的内容.

\begin{theorem}{反函数定理}{}
    设 $D\subset \mathbb{R}^n$ 为开集，$f: D\to\mathbb{R}^n$ 为 $C^{k}$ 的映射 $(k\geqslant 1)$，$x_0\in D$. 如果 $\det Jf(x_0)\neq 0$，那么存在 $x_0$ 的邻域 $U\subset D$ 与 $f(x_0)$ 的邻域 $V\subset D$ 使得 $\left.f\right|_U: U\to V$ 是可逆的，并且其逆也是 $C^k$ 的.
\end{theorem}

\begin{proof}

    由于平移不改变函数的可微性与可逆性，所以我们不失一般性地设 $(x_0, y_0) = (0, 0)$，记 $L$ 为 $f$ 在 $x_0 = 0$ 处的微分，则 $L$ 可逆，那么根据链式法则，$L^{-1}\circ f$ 在 $x_0$ 处的微分是恒同映射. 如果欲证结论对于 $L^{-1}\circ f$ 成立，那么套上一个可逆的线性映射 $L$ 之后，对于 $f$ 也一定成立. 因此我们可以直接就假设 $Jf(x_0) = I_n$.

    在 $x_0 = 0$ 附近，$g$ 是恒同映射的小扰动：\[g(x) = f(x) - x,\enspace Jg(0) = 0.\]
    扰动项 $g$ 自然也是 $C^k$ 的，因此存在 $\delta > 0$，使得\[\Vert Jg(x)\Vert \leqslant \frac{1}{2},\enspace \forall x\in \overline{B(0, \delta)}\subset D.\]
    由拟微分中值定理可知：\[\vert g(x_1) - g(x_2)\vert \leqslant \frac{1}{2}\vert x_1 - x_2\vert,\enspace \forall x_1, x_2\in \overline{B(0, \delta)}.\]
    给定 $y\in B(0, \frac{\delta}{2})$，我们在 $B(0, \delta)$ 中解方程 \[f(x) = y,\enspace\text{亦即}\enspace x = y - g(x).\]
    特别地，取 $x_2 = 0$，那么 \[\vert g(x_1) \vert \leqslant \frac{1}{2}\vert x_1\vert.\]
    记 $\varphi(x) = y - g(x)$，当 $x\in \overline{B(0, \delta)}$ 时\[\vert \varphi(x)\vert \leqslant \vert y\vert +\vert g(x)\vert < \frac{\delta}{2} + \frac{1}{2} \leqslant \delta.\]
    这说明 $\varphi(\overline{B(0, \delta)})\subset B(0, \delta)$. 当 $x_1, x_2\in \overline{B(0, \delta)}$ 时\[\vert \varphi(x_1) - \varphi(x_2) \vert = \vert g(x_2) - g(x_1)\vert \leqslant \frac{1}{2}\vert x_2 - x_1\vert.\]
    根据压缩映射原理，$f(x) = y$ 或 $x = y - g(x)$ 在 $\overline{B(0, \delta)}$ 中有唯一解，记作 $x_y$. 且 $\vert x_y\vert \leqslant \delta$，也就是 $x_y\in B(0, \delta)$. 令\[U = f^{-1}(B(0, \frac{\delta}{2}))\cap B(0, \delta),\enspace V = B(0, \frac{\delta}{2}),\]
    则我们已经证明了 $\left.f\right|_U: U\to V$ 是一一映射，其逆映射 $h(y) = x_y$ 满足 \[y - g(h(y)) = h(y)\]
    下面逐步证明 $h$ 是 $C^k$ 的.

    \begin{enumerate}
        \item[(1)] $h: V\to U$ 是连续映射：当 $y_1,y_2\in V$ 时，\[\vert h(y_1) - h(y_2)\vert \leqslant \vert y_1 - y_2 \vert +\vert g(h(y_1)) - g(h(y_2))\vert \leqslant \vert y_1 - y_2\vert + \frac{1}{2}\vert h(y_1) - h(y_2)\vert,\]
        这说明 $\vert h(y_1) - h(y_2)\vert \leqslant 2\vert y_1 - y_2\vert,\enspace \forall y_1, y_2\in V$. 所以 $h$ 是连续的.
        \item[(2)] $h: V\to U$ 是可微映射：设 $y_0\in V$，则对 $y\in V$ 有
            \[\begin{aligned}
                h(y) - h(y_0) &= (y - y_0) - [g(h(y)) - g(h(y_0))]\\
                &= (y - y_0) - Jg(h(y_0))(h(y) - h(y_0)) + o(\vert h(y) - h(y_0)\vert).
            \end{aligned}\]
            利用 $Jf = I_n = Jg$ 与 (1)，上式可以改写为\[Jf(h(y_0))\cdot(h(y) - h(y_0)) = y - y_0 + o(\vert y - y_0\vert),\]
            所以 \[h(y) - h(y_0) = Jf(h(y_0))^{-1}\cdot(y - y_0) + o(\vert y - y_0\vert)\]
            因而 $h$ 在 $y_0$ 处可微.
        \item[(3)] $h: V\to U$ 是 $C^k$ 的：由 (2) 有 $Jh(y) = Jf(h(y))^{-1},\enspace \forall y\in V$. 由于 $f$ 是 $C^k$ 的知 $Jf$ 是 $C^{k-1}$ 的. 由上知 $Jh$ 连续，所以 $h$ 是 $C^2$ 的，以此类推就可得到 $h$ 是 $C^k$ 的.
    \end{enumerate}

    这样就完成了证明.
\end{proof}

利用反函数定理，我们甚至可以利用它研究隐函数. 所谓“隐”函数，对于一个函数 $f(x, y)$ 来说，就是方程 $f(x, y) = c$ 实际上隐含的将 $y$ 定义为 $x$ 的函数，\term{隐函数定理}具体将这个函数构造了出来，下面是一个很有启发性的例子：

\begin{example}{}{}
    设 $f:\mathbb{R}^2\to\mathbb{R}^2$ 为 $C^{k}$ 函数，$k\geqslant 1$， $\frac{\partial f}{\partial y}(x^0, y^0)\neq 0$，在 $(x^0, y^0)$ 附近解方程 $f(x, y) = f(x_0, y_0)$.
\end{example}

\begin{solution}
    显然 $(x_0, y_0)$ 是方程的解，利用反函数定理，我们可以在 $(x_0, y_0)$ 附近找到别的解，因此构造函数\[F:\mathbb{R}^2\to \mathbb{R}^2,\enspace F(x, y) = (x, f(x, y)),\]
    在 $(x^0, y^0)$ 处，有 \[\det JF(x^0, y^0) = \begin{vmatrix}
        1 & 0 \\
        \dfrac{\partial f}{\partial x}(x^0, y^0) & \dfrac{\partial f}{\partial y}(x^0, y^0)
    \end{vmatrix} = \dfrac{\partial f}{\partial y}(x^0, y^0)\neq 0.\]
    由反函数定理，在 $(x^0, y^0)$ 附近 $F$ 为可逆映射. 于是当 $x$ 在 $x^0$ 附近时，记 \[F^{-1}(x, f(x^0, y^0)) = (\varphi(x), \psi(x)),\]
    则 $\varphi(x)$ 与 $\psi(x)$ 均为 $C^k$ 函数. 根据 $F$ 的定义可得 \[(\varphi(x), f(\varphi(x), \psi(x))) = (x, f(x^0, y^0)).\]
    这说明 $\varphi(x) = x$，并且 $f(x, \psi(x)) = f(x^0, y^0)$，所以 $\psi(x)$ 就是我们要找的隐函数. 对 $x$ 求导还可以得到 \[\frac{\partial f}{\partial x}(x, \psi(x)) + \frac{\partial f}{\partial y}(x, \psi(x))\psi'(x) = 0,\]
    从而有 \[\psi'(x) = -[\frac{\partial f}{\partial y}(x, \psi(x))]^{-1}\frac{\partial f}{\partial x}(x, \psi(x)).\]
    这就给出了对 $y = \psi(x)$ 的刻画.
\end{solution}

这个例子可以很轻松地推广到一般形式，只需要将偏导数换成雅各布矩阵，这就是隐函数定理的内容. 但在正式介绍隐函数定理之前，我们看一下它线性的说法：

\begin{example}{}{}
    如果 $x = (x_1, x_2, \cdots, x_n)\in\mathbb{R}^n$ 而 $y = (y_1, y_2, \cdots, y_m)\in\mathbb{R}^m$，我们将一个点（或者说向量）$(x_1, \cdots, x_n, y_1, \cdots, y_m)\in \mathbb{R}^{n+m}$ 记作 $(x, y)$，那么每一个线性映射 $A\in L(\mathbb{R}^{n+m}, \mathbb{R}^{m})$ 可以被表示成两个线性映射 $A_x$ 和 $A_y$ 的“拼接”，分别由 \[A_xh = A(h, 0),\enspace A_yk = A(0, k)\]
    确定，其中 $h\in\mathbb{R}^n$，$k\in\mathbb{R}^m$，并且 $A_x\in L(\mathbb{R}^n, \mathbb{R}^m)$，$A_y\in L(\mathbb{R}^m)$. 并且有 \[A(h, k) = A_xh + A_yk.\]
    如果 $A_y$ 是可逆的，那么对于每一个 $x\in\mathbb{R}^n$，存在唯一的 $y\in\mathbb{R}^m$ 使得 $A(x, y) = c$，这里的 $c\in\mathbb{R}^m$. 更进一步地，这个 $y$ 可以利用公式 \[y = -[A_y]^{-1}A_x(x) + [A_y]^{-1}c\] 确定.
\end{example}

这个例子直观且很容易证明，所以证明就此略去. 进行一些略微不严谨的思考：对于方程 $A(x, y) = c$ 来说，我们将其视为一个线性的隐函数，等式右边可以确定一个 $m$ 维的空间中的点，所以“提供了 $m$ 维的信息”，因此左侧就是一个“余 $m$ 维”式子，因此可以根据 $n$ 维的点来确定另外一个 $m$ 维的点. 现在来看隐函数定理，你会惊奇地发现隐函数定理的形式与隐函数为线性时的情况是如此相似.

\begin{theorem}{隐函数定理}{}
    设 $W\subset \mathbb{R}^{n+m}$ 为开集，$W$ 中的点用 $(x, y)$ 表示，其中 $x = (x_1, x_2, \cdots, x^n), \enspace y = (y_1, y_2, \cdots, y_m)$，$f:W\to \mathbb{R}^m$ 为 $C^k$ 映射，用分量表示为 \[f(x, y) = (f_1(x, y), f_2(x, y), \cdots, f_m(x, y)).\]
    设 $(x^0. y^0)\in W$， 且 $\det J_y(x^0, y^0)\neq 0$，其中 $J_y(x, y) = \left(\frac{\partial f_i}{\partial x_j}(x, y)\right)_{m\times n}$. 则存在 $x^0$ 的开邻域 $V\subset \mathbb{R}^n$ 以及唯一的 $C^k$ 映射 $\psi: V\to \mathbb{R}^m$，使得\begin{enumerate}
        \item[(1)] $\psi(x^0) = y^0,\enspace f(x, \psi(x)) = f(x^0, y^0),\enspace \forall x\in V$；
        \item[(2)] $J\psi(x) = -[J_yf(x, \psi(x))]^{-1}J_xf(x, \psi(x))$，其中 $J_xf(x, y) = \left(\frac{\partial f_i}{\partial x_j}(x, y)\right)_{m\times n}$.
    \end{enumerate}
\end{theorem}

反函数定理与隐函数定理对函数在 $(x^0, y^0)$ 时的微分 $J_*f(x^0, y^0)$ （这里的 $*$ 表示隐函数对 $y$ 求微分）有着很高的要求，亦即要求它是可逆也就是\term{满秩}的，那么如果这个微分不满秩呢？下面的\term{秩定理}. 我们还是先回忆一点关于线性变换的事实.

\begin{theorem}{射影}{}
    对于一个线性空间 $X$ 上的线性变换 $P\in L(X)$ 满足 $P^2 = P$，那么称 $P$ 为 $X$ 里的一个\term{射影}. 射影满足下面的性质：
    \begin{enumerate}
        \item[(1)] 每一个 $x\in X$ 都可以唯一表示成 $x = x_1+x_2$ 的形式，其中 $x_1\in\mathrm{im}A$，$x_2\in\ker A$；
        \item[(2)] 如果 $X$ 是有限维的线性空间，$X_1$ 是 $X$ 内的一个线性子空间，那么在 $X$ 中存在一个射影 $P$ 使得 $\mathrm{im}P = X_1$.
    \end{enumerate}
\end{theorem}

\begin{proof}
    \begin{enumerate}
        \item[(1)] 令 $x_1 = Px$，$x_2 = x - Px$，则 $Px_2 = Px - Px_1 = Px - P^2x = 0$，所以 $x_2\in\ker P$. 将 $P$ 作用在 $x = x_1 + x_2$ 上，有 $Px = Px_1 + Px_2 = Px_1$，所以 $x_1 = Px$，这就证明了表示的唯一性.
        \item[(2)]  如果 $X = \{0\}$，那么这是显然的. 于是我们假设 $\dim X_1 = k >0$，取 $X$ 的某个基 $\{u_1, u_2, \cdots, u_n\}$ 使得 $\{u_1, u_2, \cdots, u_k\}$ 是 $X_1$ 的基，那么我们可以定义 $P$ 使得 $P(u_1) = u_1, P(u_2) = u_2, \cdots, P(u_k) = u_k$，并且 $P(u_{k+1}) = P(u_{k+2}) = \cdots = P(u_n) = 0$，这样就构造出了一个射影.
    \end{enumerate}
\end{proof}

\begin{theorem}{秩定理}{}
    
\end{theorem}

\begin{proof}

\end{proof}

\section{积分学}

多元函数的积分学中的核心定理主要是 Fubini 定理与重积分换元法.

在介绍重积分换元法之前，我们先考虑重积分换元法的核心——坐标变换. 坐标变换以链式法则为前提，我们在很早之前就接触到了坐标变换，比如极坐标与 Descartes 坐标系之间的转换，我们首先使用映射的语言描述极坐标：

\begin{example}{坐标变换}{}
    对于定义区域 $\Omega_1$ 和 $\Omega_2$ 如下：
    \[\Omega_1 = \mathbb{R}^2\setminus\{(x, y)\vert x\geqslant 0, y = 0\},\enspace \Omega_2 = \mathbb{R}_{>0}\times (0, 2\pi) = \{(r, \vartheta)\vert r>0, \vartheta\in(0, 2\pi)\}.\]
    我们熟悉的坐标变换 $x = r\cos\vartheta$，$y = r\sin\vartheta$ 就可以写成 \[\Phi: \Omega_2\to\Omega_1,\enspace \Phi(r, \vartheta) = (r\cos\vartheta, r\sin\vartheta).\]（这里要有一个图）
    由于在 $\Omega_1$ 上我们给定了 $(x, y)$ 作为坐标，在$\Omega_2$ 上我们给定了 $(r, \vartheta)$ 作为坐标，所以我们可以使用 Jacobi 矩阵表示上述映射的微分
    \[
        \mathrm{d}\Phi = J\Phi = \begin{pmatrix}
            \frac{\partial x}{\partial r} & \frac{\partial x}{\partial \vartheta} \\
            \frac{\partial y}{\partial r} & \frac{\partial y}{\partial \vartheta}
        \end{pmatrix} = \begin{pmatrix}
            \cos\vartheta & -r\sin\vartheta \\
            \sin\vartheta & r\cos\vartheta
        \end{pmatrix}
    \]
    根据反函数定理，这个映射当然是可逆的.
\end{example}

这个例子告诉我们：坐标变换允许我们将被积区域进行变换，比如将圆或球转化成一个矩形，这样就可以极大简化运算. 更确切来说，对于原被积区域 $\Omega$ 上的函数 $f$，我们可以定义一个映射 $\varphi: \Sigma \to \Omega,\enspace \varphi(\Sigma) = \Omega$，使得我们只需要在现被积区域 $\Sigma$ 对复合函数 $f\circ\varphi$ 进行积分，函数的复合保证了积分区域转换的合法性，但是我们并不可以草率进行 $\displaystyle\int_{\Omega}f\,\mathrm{d}x = \displaystyle\int_{\Sigma}f\circ \varphi\,\mathrm{d}x$ 的计算，因为对于 $\Omega$ 上的某一块体积元 $\sigma$，对与 $f$ 与坐标变换 $\varphi$ 下对应的 $\Sigma$ 上的体积元 $\sigma'$ 的体积并不一定相等，就好像对于上面例子中，将圆转化为矩形一样. 那么体积究竟变化了多少呢？这就是下面重积分换元法将要讨论的事情了.

下面，我们首先考虑坐标变换为线性映射的情况，再使用微分学的基本手法对一般的坐标变换做线性化并且估计误差.

(1) 平移变换. 设 $\vec{v_0}$ 为一个固定的向量，

(2) 伸缩变换.

\begin{lemma}{第一覆盖引理}{}
    （这里需要一个图图）

\end{lemma}

\begin{theorem}{}{}

\end{theorem}

(3) 正交变换

\begin{lemma}{第二覆盖引理}{}

\end{lemma}

\begin{theorem}{}{}

\end{theorem}

(4) 一般的线性变换

\begin{theorem}{}{}

\end{theorem}


\begin{lemma}{}{}

\end{lemma}

\begin{lemma}{}{}

\end{lemma}

\begin{lemma}{}{}

\end{lemma}

\begin{theorem}{重积分换元法}{}

\end{theorem}

\vspace{2ex}
\centerline{\heiti \Large 内容总结}

\vspace{2ex}
\centerline{\heiti \Large 习题}

\vspace{2ex}
{\kaishu }
\begin{flushright}
    \kaishu

\end{flushright}

\centerline{\heiti A组}
\begin{enumerate}
    \item
\end{enumerate}

\centerline{\heiti B组}
\begin{enumerate}
    \item
\end{enumerate}

\centerline{\heiti C组}
\begin{enumerate}
    \item
\end{enumerate}
